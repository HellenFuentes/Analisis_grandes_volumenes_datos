{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb20836e-7f8e-44bb-8106-ac257eeb0b92",
   "metadata": {},
   "source": [
    "## Ejemplo de Bloom Filters\n",
    "\n",
    "Créditos\n",
    "\n",
    "Curso *[CS246](https://web.stanford.edu/class/cs246/): Mining Massive Data Sets*, Prof. J. Leskovec\n",
    "\n",
    "Se muestra el uso de un Filtro de Bloom sencillo y se provee una breve comparación de desempeño respecto de soluciones alternativas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febd5aa-7885-4555-bfe3-9aaa8401fda8",
   "metadata": {},
   "source": [
    "### Requisitos\n",
    "\n",
    "1. Implementación de [Bloom Filter](https://github.com/hiway/python-bloom-filter) o su alternativa [Bloom Filter 2](https://pypi.org/project/bloom-filter2/)  \n",
    "1. [Natural Language Toolkit](https://www.nltk.org/index.html)\n",
    "\n",
    "```\n",
    "$ pip install bloom_filter   \n",
    "$ pip install nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75778a-19aa-45f2-b4aa-abd54266d00f",
   "metadata": {},
   "source": [
    "__Data sets__\n",
    "\n",
    "Importar una lista de palabras de nltk y un data set sobre *movie reviews*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ac09a6-be4a-4beb-bdad-f55f06e38287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/ecciadm/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/ecciadm/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3461ac5-ee83-4c98-b718-bbb82e3c4c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary length: 236736\n",
      "['wing', 'winter', 'wire', 'wise', 'with', 'woman', 'wood', 'wool', 'word', 'work', 'worm', 'wound', 'writing', 'wrong', 'year', 'yellow', 'yes', 'yesterday', 'you', 'young']\n"
     ]
    }
   ],
   "source": [
    "word_list = words.words()\n",
    "print(f'Dictionary length: {len(word_list)}')\n",
    "print(word_list[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf3e37-5e0f-4c7f-b5e5-b0a04aaa9c80",
   "metadata": {},
   "source": [
    "Separar la lista de palabras según su connotación positiva o negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb9a103-b5c5-4782-acd9-f4ff965cfbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reviews = []\n",
    "pos_reviews = []\n",
    "\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "  neg_reviews.extend(movie_reviews.words(fileid))\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "  pos_reviews.extend(movie_reviews.words(fileid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e1d5a-4e9c-4f4a-a358-4e1973cbe44e",
   "metadata": {},
   "source": [
    "__Task__\n",
    "\n",
    "Crear un revisor ortográfico de juguete para poner en práctica el uso del filtro bloom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "185b9ed0-7b1d-4ecd-9ce6-37cbb74d2c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloom_filter import BloomFilter\n",
    "\n",
    "word_filter = BloomFilter(max_elements=236736)\n",
    "\n",
    "for word in word_list:\n",
    "  word_filter.add(word)\n",
    "\n",
    "word_set = set(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225cd8a-b193-4717-86ea-560196dcb028",
   "metadata": {},
   "source": [
    "Ahora tenemos 3 variables con datos\n",
    "\n",
    "1.```word_list```, una lista en Python con el diccionario de palabras que descargamos (*case sensitive*)  \n",
    "2.```word_filter```, un Filtro de Bloom que ya tiene todas las palabras del diccionario  \n",
    "3.```word_set```, un [Python set](https://docs.python.org/3.6/library/stdtypes.html#set-types-set-frozenset) que también tiene las palabras del diccionario  \n",
    "\n",
    "Podemos ver el tamaño de cada estructura de datos mediante [getsizeof()](https://docs.python.org/3/library/sys.html#sys.getsizeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a772ea67-4d35-487e-bfce-512f34ca308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word_list (in bytes): 2115944\n",
      "Size of word_filter (in bytes): 48\n",
      "Size of word_set (in bytes): 8388824\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "swlist = getsizeof(word_list)\n",
    "swfilter = getsizeof(word_filter)\n",
    "swset = getsizeof(word_set)\n",
    "\n",
    "print(f'Size of word_list (in bytes): {swlist}')\n",
    "print(f'Size of word_filter (in bytes): {swfilter}')\n",
    "print(f'Size of word_set (in bytes): {swset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3384b-918e-4271-83a2-c40c8b9c749a",
   "metadata": {},
   "source": [
    "Se puede notar lo eficiente que es el Filtro Bloom en uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b03c2d2-f745-4641-abf9-8a029c3b3b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44082.17 Más pequeño que la lista\n",
      "174767.17 Más pequeño que el set\n"
     ]
    }
   ],
   "source": [
    "print(f'{swlist/swfilter:.2f} Más pequeño que la lista')\n",
    "print(f'{swset/swfilter:.2f} Más pequeño que el set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a25c036-c607-4fb9-bc25-d18822e5e761",
   "metadata": {},
   "source": [
    "El Filtro de Bloom está hecho para realizar una operación especial que es probar la membresía a un conjunto. \n",
    "\n",
    "Para ver qué tan rápido lo hace usamos el comando `%timeit` de `IPython` que muestra el tiempo de ejecución de forma repetida de una instrucción individual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2104cd07-cdd5-45bb-b2ac-c8a7a0b5c3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 12.09 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "2.33 ms ± 2.62 ms per loop (mean ± std. dev. of 7 runs, 3 loops each)\n",
      "16.9 µs ± 3.7 µs per loop (mean ± std. dev. of 7 runs, 3 loops each)\n",
      "141 ns ± 120 ns per loop (mean ± std. dev. of 7 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 3 \"California\" in word_list\n",
    "%timeit -n 3 \"California\" in word_filter\n",
    "%timeit -n 3 \"California\" in word_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c337c9f-4f93-4e1b-af05-d168653a37cc",
   "metadata": {},
   "source": [
    "1. `word_list` hace una búsqueda lineal  \n",
    "1. `word_filter` hace múltiples cálculos de funciones hash  \n",
    "1. `word_set` hace una sola función hash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eebb1b0-109b-4c01-994d-ffc552a17d1e",
   "metadata": {},
   "source": [
    "Con las estructuras de datos que se tienen podemos crear la base del revisor ortográfico.  \n",
    "\n",
    "La siguiente función recibe dos argumentos, el primero es una lista de palabras y la segunda es una de las estructuras de datos que tenemos. La función retorna la cantidad de palabras que no aparecen en el diccionario o estructura dada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2f7e3f0-23e0-4342-af55-a5fc7b5c0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_in_the_list(words, a_list):\n",
    "  count = 0\n",
    "  for word in words:\n",
    "    if (word not in a_list):\n",
    "      count +=1\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82389626-0539-444d-8897-940a5472e4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1 ms ± 4.64 ms per loop (mean ± std. dev. of 7 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 3 not_in_the_list([\"Aani\", \"roca\", \"tititi\", \"Ababua\"], word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40bfe12a-498c-4b06-b155-368ebdc38869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.7 µs ± 1.17 µs per loop (mean ± std. dev. of 3 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 3 not_in_the_list([\"Aani\", \"roca\", \"tititi\", \"Ababua\"], word_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63ffb649-8902-44e0-a9d6-b7cb397c3bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294 ns ± 4.07 ns per loop (mean ± std. dev. of 3 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit  -r 3 not_in_the_list([\"Aani\", \"roca\", \"tititi\", \"Ababua\"], word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827bc76-a92e-4339-93e3-b6d0aa1f6c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
